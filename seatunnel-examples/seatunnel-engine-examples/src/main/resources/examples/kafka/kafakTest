env {
	job.mode = "STREAMING"
	parallelism = "1"
	job.retry.times = "0"
	job.name = "aace8bb9f8864562b0264ea75e3991f5"
	checkpoint.interval = "180000"
}

source {
	Kafka {
		schema = {"fields":{"a1":"string","a":"string","b":"string","c":"string","d":"string","e":"string","f":"timestamp","id":"string","e1":"string","d1":"string","c1":"string","b1":"string"}}
		format = "json"
		bootstrap.servers = "10.28.23.131:9092"
		topic = "data10"
		consumer.group = "111"
		semantics = EXACTLY_ONCE
		start_mode = "earliest"
		field_delimiter = ","
		result_table_name = "tmp_table_kafka_31ad8"
	}
}

transform {
}

sink {
	MappingJdbc {
		database = "d_migrate"
		table = "aaa_test2"
		batch_size = 3000
		generate_sink_sql = true
		parallelism = 1
		field_mapper = {"a1":"a1","a":"a","b":"b","c":"c","d":"d","e":"e","f":"f","id":"id","e1":"e1","d1":"d1","c1":"c1","b1":"b1"}
		source_table_name = "tmp_table_kafka_31ad8"
		password_decrypt = true
		data_save_mode = "APPEND_DATA"
		schema_save_mode = "ERROR_WHEN_SCHEMA_NOT_EXIST"
		enable_upsert = false
		driver = "com.mysql.cj.jdbc.Driver"
		url = "jdbc:mysql://10.28.23.234:3306/d_migrate?useSSL=false&useUnicode=true&characterEncoding=utf8&allowLoadLocalInfile=false&autoDeserialize=false&allowLocalInfile=false&allowUrlInLocalInfile=false&serverTimezone=Asia/Shanghai"
		user = "u_migrate"
		password = "Lrq9Ftv6H7J1JWOElUL5XPtgC2t4lob7DlIPdHz9G5jxBlLvLB1RWBfHu0zmfkwAEQXwR6JSPx4waHzOKvohjtB8+sWs+QCtN/3ozJR7A/Wahgwa/xVxeH4gtUlZ42aWooEP+m6TbV3Fjj7Z6r7vJHDAeKILrCEM/H4Fwq5BpD0="
	}
}